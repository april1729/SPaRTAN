{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Created By  : Xiaojun Ma\n",
    "# Created Date: Mar 18 10:54:00 PDT 2020\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "This script contains the major class of SPaRTAN model and its dependencies.\n",
    "This script requires numpy, Scipy, matplotlib to be installed within the Python\n",
    "environment you are running this script in\n",
    "This script requires Cython modules present in the current directory\n",
    "This file contains the following classes and functions\n",
    "   \n",
    "    class Timer: a class to convert time period in seconds to the format of h:m:s\n",
    "   \n",
    "    class pySPaRTAN: The major class for SPaRTAN, establishing an interaction matrix between\n",
    "    surface proteins (P) and TFs (D) that predict target gene expression (Y).\n",
    "   \n",
    "    function normalize_column(): perform l2 normalization column-wize of given matrix\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cythKronPlus as krnP\n",
    "import cythLeastR as leastR\n",
    "import scipy.linalg\n",
    "import functools\n",
    "import time\n",
    "import gc\n",
    "# import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "class Timer:\n",
    "    \"\"\" a class to convert time in seconds to the format of h:m:s\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    def __init__(self):\n",
    "        initiate a timer\n",
    "    def restart(self):\n",
    "        restart a timer\n",
    "    def get_time_hhmmss(self):\n",
    "        return the period = end_time - start_time in (h, m, s) format\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # initiate a timer\n",
    "        self.start = time.time()\n",
    "\n",
    "    def restart(self):\n",
    "        # restart a timer\n",
    "        self.start = time.time()\n",
    "\n",
    "    def get_time_hhmmss(self):\n",
    "        # return the period = end_time - start_time\n",
    "        # in (h, m, s) format\n",
    "        end = time.time()\n",
    "        m, s = divmod(end - self.start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "        return time_str\n",
    "\n",
    "\n",
    "def normalize_column(A, T=0):\n",
    "    \"\"\" perform l2 normalization column-wize of given matrix\n",
    "    \n",
    "    Parameters:\n",
    "        A : the matrix that works on\n",
    "        T : switch of column-wize and row-wize.\n",
    "            T=0: column-wize\n",
    "            T=1: row-wize\n",
    "            \n",
    "    \"\"\"\n",
    "    if (T == 0):\n",
    "        return np.divide(A, np.sqrt(np.sum(A**2, 0)))\n",
    "    else:\n",
    "        At = np.transpose(A)\n",
    "        return np.transpose(np.divide(At, np.sqrt(np.sum(At**2, 0))))\n",
    "\n",
    "\n",
    "class pySPaRTAN:\n",
    "    \"\"\"\n",
    "    The major class for SPaRTAN, establishing an interaction matrix between\n",
    "    surface proteins (P) and TFs (D) that predicts target gene expression (Y).\n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, D, P, Y, lamda=0.001, rsL2=0.001,\n",
    "        spectrumP=0.7):\n",
    "        train a SPaRTAN model\n",
    "    ar_model2w(self):\n",
    "        converts a trained model to intermidiat vaiable W\n",
    "    ar_reconstruction(self, pred_test=None):\n",
    "        reconstruction function\n",
    "    predict(self, P_test=None):\n",
    "        predict target gene expression\n",
    "    get_corr(self, Y_pred, Y_test, plot=False):\n",
    "        get the correlation between predicted Y_pred and Y_test\n",
    "    get_W(self):\n",
    "        get coefficient matrix\n",
    "    get_projP(self, Y=None):\n",
    "        get projected protein expression\n",
    "    get_projD(self, P=None):\n",
    "        get projected TF activity\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, D, P, Y, lamda=0.001, rsL2=0.001, corrtype='spearman'):\n",
    " \n",
    "        \"\"\" trains a SPaRTAN model\n",
    "        Parameters\n",
    "        ----------\n",
    "        D : array of shape (N, Q)\n",
    "            The data matrix with N genes and Q TFs\n",
    "        P : array of shape (M, S)\n",
    "            The data matrix with M cells and S proteins \n",
    "            \n",
    "        Y : array of shape (N, M)\n",
    "            The data matrix with N genes and M cells \n",
    "            \n",
    "        lamda : float > 0, default=0.001\n",
    "            LASSO regularization for linear regression \n",
    "            \n",
    "        rsL2 : float > 0, default=0.001\n",
    "            ridge regularization for linear regression\n",
    "            \n",
    "        corrtype: string, default='spearman'\n",
    "            correlation type used to evaluate the performance\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        spectrumA = 1\n",
    "        spectrumP = 0.7\n",
    "\n",
    "        self.D = D\n",
    "        self.P = P\n",
    "        self.Y = Y\n",
    "        self.corrtype = corrtype\n",
    "\n",
    "        # transformation\n",
    "        A = self.Y.T @ self.D\n",
    "        B = self.P.T\n",
    "        Y = self.Y.T @ self.Y\n",
    "\n",
    "        # SVD(A) SVD(B)\n",
    "        UA, SA, VhA = np.linalg.svd(A)\n",
    "        VA = VhA.T\n",
    "        UB, SB, VhB = np.linalg.svd(B)\n",
    "        VB = VhB.T\n",
    "\n",
    "        a_cum_spectrum = np.cumsum(SA) / sum(SA)\n",
    "        b_cum_spectrum = np.cumsum(SB) / sum(SB)\n",
    "\n",
    "        da = np.nonzero(a_cum_spectrum >= spectrumA)[0][0] + 1\n",
    "        db = np.nonzero(b_cum_spectrum >= spectrumP)[0][0] + 1\n",
    "\n",
    "        Ua = UA[:, :da]\n",
    "        Sa = SA[:da]\n",
    "        Va = VA[:, :da]\n",
    "\n",
    "        Ub = UB[:, :db]\n",
    "        Sb = SB[:db]\n",
    "        Vb = VB[:, :db]\n",
    "\n",
    "        Yv = (Y.T).flatten()\n",
    "\n",
    "        Vb = Vb.copy(order='C')\n",
    "        Ua = Ua.copy(order='C')\n",
    "        L = krnP.kron(Vb, Ua)\n",
    "\n",
    "        d = np.eye(Y.shape[0], Y.shape[1])\n",
    "        cidex = np.where(d.flatten() != 0)\n",
    "        diag = np.array(cidex, dtype=np.int32).flatten()\n",
    "\n",
    "        # make it c-like contiguous array\n",
    "        Yv = Yv.copy(order='C')\n",
    "        diag = diag.copy(order='C')\n",
    "\n",
    "        L, Yv = krnP.removeDiagC(L, Yv, diag)\n",
    "\n",
    "        opts = dict()\n",
    "        opts['rsL2'] = rsL2\n",
    "\n",
    "        # reshape Yv to 2darry\n",
    "        Yv = Yv.reshape(Yv.shape[0], 1)\n",
    "        beta, b = leastR.LeastR(L, Yv, lamda, opts)\n",
    "\n",
    "        del L, Yv\n",
    "        gc.collect()\n",
    "\n",
    "        self.beta = beta\n",
    "        self.Ua = Ua\n",
    "        self.Ub = Ub\n",
    "        self.Sa = np.diag(Sa)\n",
    "        self.Sb = np.diag(Sb)\n",
    "        self.Va = Va\n",
    "        self.Vb = Vb\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def ar_model2w(self):\n",
    "        # converts a trained model to W\n",
    "        m1 = self.Va\n",
    "        m2 = np.linalg.pinv(self.Sa)\n",
    "        m3 = self.beta.reshape(self.Va.shape[1], self.Ub.shape[1], order=\"F\")\n",
    "        m4 = np.linalg.pinv(self.Sb)\n",
    "        m5 = self.Ub.T\n",
    "        ww = m1 @ m2 @ m3 @ m4 @ m5\n",
    "        return ww\n",
    "\n",
    "    def ar_reconstruction(self, pred_test=None):\n",
    "        \"\"\" reconstruction function\n",
    "        Parameters\n",
    "        ----------\n",
    "        pred_test: prediction on test data\n",
    "        \n",
    "        \"\"\"\n",
    "        A = self.Y.T @ pred_test\n",
    "        B = scipy.linalg.orth(self.Y)\n",
    "        cm = scipy.linalg.lstsq(B, self.Y)[0]\n",
    "        ct = scipy.linalg.lstsq(cm.T, A)[0]\n",
    "        pred = B @ ct\n",
    "        return pred\n",
    "\n",
    "    def predict(self, P_test=None):\n",
    "        \"\"\" predict target gene expression\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        P_test: Protein expression on test data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y_pred: array of shape (N, Mtest)\n",
    "                The predicted Y matrix on test data set which has N genes and Mtest cells\n",
    "        \n",
    "        \"\"\"\n",
    "        if P_test is not None:\n",
    "            self.P_test = P_test\n",
    "\n",
    "        w = self.ar_model2w()\n",
    "        pred = self.D @ (w @ self.P_test.T)\n",
    "\n",
    "        aff_rec = self.ar_reconstruction(pred)\n",
    "\n",
    "        self.Y_pred = aff_rec\n",
    "        return self.Y_pred\n",
    "\n",
    "    def get_corr(self, Y_pred, Y_test):#, plot=False):\n",
    "        \"\"\" get the correlation between predicted Y_pred and Y_test\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y_pred: array of shape (N, Mtest)\n",
    "                predicted gene expression with N genes and Mtest cells\n",
    "                \n",
    "        Y_test: array of shape (N, Mtest)\n",
    "               gene expression test data with N genes and Mtest cells\n",
    "       # plot: whether to plot the correlation between Y_pred and Y_test, default is False\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        corr: float 0 <= value <= 1\n",
    "              spearman/pearson corrlatioin between flattened Y_pred and Y_test\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.corrtype == 'spearman':\n",
    "            corr = stats.spearmanr(Y_test.ravel(order='F'), Y_pred.ravel(order='F'))[0]\n",
    "        else:\n",
    "            corr = stats.pearsonr(Y_test.ravel(order='F'), Y_pred.ravel(order='F'))[0]                           \n",
    "\n",
    "#         if plot:\n",
    "#             plt.plot(Y_test.ravel(order='F'), Y_pred.ravel(order='F'),\n",
    "#                      linestyle='none', marker='+')\n",
    "#             plt.title('reconstruction of Y test, corr={:.2f}'.format(corr))\n",
    "\n",
    "        return corr\n",
    "\n",
    "    def get_W(self):\n",
    "        # get coefficient matrix\n",
    "        \n",
    "        self.W = self.ar_model2w()\n",
    "        return self.W\n",
    "\n",
    "    def get_projP(self, Y=None):\n",
    "        \"\"\" get projected protein expression\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y:  array of shape (optional, default is (N, M) )\n",
    "            input gene expression with N genes and M cells\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        projP: array of shape (M, S)\n",
    "               projected protein expression with M cells and S proteins\n",
    "               \n",
    "        \"\"\"\n",
    "        if Y is None:\n",
    "            Y = self.Y\n",
    "        W = self.ar_model2w()\n",
    "        return (Y.T @ self.D @ W).T\n",
    "\n",
    "    def get_projD(self, P=None):\n",
    "        \"\"\" get projected TF activity\n",
    "        Parameters\n",
    "        ----------\n",
    "        P: array of shape (optional, default is (M, S) )\n",
    "           input protein expression with M cells and S proteins\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        projD:  array of shape (Q, M) \n",
    "            projected TF activities with Q TFs and M cells\n",
    "            \n",
    "        \"\"\"\n",
    "              \n",
    "        if P is None:\n",
    "            P = self.P\n",
    "        W = self.ar_model2w()\n",
    "        return W @ P.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This script intends to use pySPaRTAN module to generate predicted matrices used in the paper.\n",
    "Input data\n",
    "----------\n",
    "D: dataframe of shape (N, Q)\n",
    "   The data frame with N genes and Q TFs\n",
    "   \n",
    "P: dataframe of shape (M, S)\n",
    "   The data frame with M cells and S proteins  \n",
    "   \n",
    "Y: array of shape (N, M)\n",
    "   The data frame with N genes and M cells\n",
    "   \n",
    "location: default in the directory ../data/inputs\n",
    "   \n",
    "Output data\n",
    "-----------\n",
    "projD: dataframe of shape (Q, M) \n",
    "       projected TF activities with Q TFs and M cells \n",
    "       \n",
    "projP: dataframe of shape (S, M)\n",
    "      projected protein expression with S proteins and M cells    \n",
    "     \n",
    "location: location: default in the directory ../data/outputs\n",
    " \n",
    "Hyperparameters\n",
    "---------------\n",
    "      \n",
    "pySPaRTAN has 2 Hyperparameters that can be adjusted: lamda and rsL2\n",
    "We can run pySPaRTAN by specifying some values to those parameters or using default ones in the script.\n",
    "We can also use cross-validation at first to get the optional values for those\n",
    "hyperparameters, and then run pySPaRTAN to generate the projections.\n",
    "Command lines\n",
    "-------------\n",
    "When running this script from command line, the following parameters can be added to the command:\n",
    "    \n",
    "    --input_dir : directory of input files, default=\"../data/inputs\"\n",
    "    \n",
    "    --output_dir : directory of output files, default=\"../data/outputs\"\n",
    "    \n",
    "    --dataset_D : dataframe of gene X TF \n",
    "                  Requires .csv format, only contains file name, not include \".csv\" extension\n",
    "                  \n",
    "    --dataset_P : dataframe of cell X protein\n",
    "                  Requires .csv format, only contains file name, not include \".csv\" extension\n",
    "        \n",
    "    --dataset_Y : dataframe of gene X cell\n",
    "                  Requires .csv format, only contains file name, not include \".csv\" extension\n",
    "                  \n",
    "    --lamda :  float > 0.0, default=0.001\n",
    "            LASSO regularization for linear regression \n",
    "            \n",
    "    --rsL2 : float > 0.0, default=0.001\n",
    "            ridge regularization for linear regression\n",
    "            \n",
    "    --normalization : string, default = \"l2\"\n",
    "                     type of normalizion performed on matrices,\n",
    "                     if set to \"\", then no normalization\n",
    "                     \n",
    "    --fold : int >=0, default = 0\n",
    "             how many folds to be used when doing cross-validation.\n",
    "             if set to 0, it means using default/specified hyper-parameters, \n",
    "             do not conduct cross-validation\n",
    " \n",
    "    --correlation : string, (\"pearson\" or \"spearman\") default = \"pearson\"\n",
    "                    type of correlation coefficient\n",
    "                     \n",
    "System requirements\n",
    "------------------                         \n",
    "This script requires numpy, pandas, sklearn to be installed in the python running environment\n",
    "\"\"\"\n",
    "from argparse import ArgumentParser, RawTextHelpFormatter\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from pySPaRTAN import pySPaRTAN\n",
    "\n",
    "print(\"Read in datasets D, P, and Y ...\")\n",
    "D_ori = pd.read_csv(os.path.join(args.input_dir, args.dataset_D+'.csv'), index_col=0)\n",
    "P_ori = pd.read_csv(os.path.join(args.input_dir, args.dataset_P+'.csv'), index_col=0)\n",
    "Y_ori = pd.read_csv(os.path.join(args.input_dir, args.dataset_Y+'.csv'), index_col=0)\n",
    "\n",
    "TF_name = list(D_ori.columns)\n",
    "cell_name = list(Y_ori.columns)\n",
    "gene_name = list(Y_ori.index)\n",
    "protein_name = list(P_ori.columns)\n",
    "\n",
    "D_mat = D_ori.values\n",
    "P_mat = P_ori.values\n",
    "Y_mat = Y_ori.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize the dataset\n",
    "if args.normalization != \"\":\n",
    "    D_mat = normalize(D_mat, norm=\"l2\", axis=0)\n",
    "    Y_mat = normalize(Y_mat, norm=\"l2\",axis=0)\n",
    "    P_mat = normalize(P_mat, norm=\"l2\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the object of SPaRTAN\n",
    "reg = pySPaRTAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cross-validate to determine optimal parameters\n",
    "fold = 0\n",
    "if fold != 0:  # using cross validation to determine the optimal parameters\n",
    "    \n",
    "    lamdas = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    rsL2s = [0.001, 0.01, 0.1]\n",
    "\n",
    "    lenlamdas = len(lamdas)\n",
    "    lenrsL2s = len(rsL2s)\n",
    "    \n",
    "    corr_all = np.zeros((lenlamdas, lenrsL2s))\n",
    "\n",
    "    for l in range(0, lenlamdas):\n",
    "        for r in range(0, lenrsL2s):\n",
    "            print(\"cross validating lambda={}, rsL2={}\"\n",
    "                  .format(lamdas[l], rsL2s[r]))\n",
    "\n",
    "\n",
    "            Y_pred_all = np.zeros(Y_mat.shape)\n",
    "            kf = KFold(n_splits=fold)\n",
    "            for train_index, test_index in kf.split(P_mat):\n",
    "\n",
    "                # split the data into train and test set\n",
    "                P_train, P_test = P_mat[train_index, :], P_mat[test_index, :]\n",
    "                Y_train, Y_test = Y_mat[:, train_index], Y_mat[:, test_index]\n",
    "\n",
    "                # normalize the train and test set\n",
    "                if args.normalization != \"\":\n",
    "                    Y_train = normalize(Y_train, axis=0)\n",
    "                    Y_test = normalize(Y_test, axis=0)\n",
    "\n",
    "                    P_train = normalize(P_train, axis=1)\n",
    "                    P_test = normalize(P_test, axis=1)\n",
    "\n",
    "                    \n",
    "                # train the model\n",
    "                reg.fit(D_mat, P_train, Y_train, lamdas[l], rsL2s[r], args.correlation)\n",
    "\n",
    "                # get predicted value Y_pred  on P_test\n",
    "                Y_pred = reg.predict(P_test)\n",
    "\n",
    "                # save Y_pred to the whole matrix\n",
    "                Y_pred_all[:,test_index] = Y_pred\n",
    "\n",
    "\n",
    "            corr = reg.get_corr(Y_pred_all, Y_mat)\n",
    "            corr_all[l, r] = corr\n",
    "\n",
    "    # retrive the best parameters\n",
    "    max_l, max_r = np.unravel_index(\n",
    "        corr_all.argmax(), corr_all.shape\n",
    "    )\n",
    "    \n",
    "    lamda_best = lamdas[max_l]\n",
    "    rsL2_best = rsL2s[max_r]\n",
    "       \n",
    "    print(\"lamda_best={}, rsL2_best={}\"\n",
    "          .format(lamda_best, rsL2_best))\n",
    "\n",
    "else:  # fold ==0: using default/specified paramters\n",
    "\n",
    "    lamda_best = 0.01\n",
    "    rsL2_best = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing ...\")\n",
    "# re-train the model\n",
    "reg.fit(D_mat, P_mat, Y_mat, lamda_best, rsL2_best, args.correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve projD, projP\n",
    "projD = reg.get_projD()\n",
    "projP = reg.get_projP()\n",
    "\n",
    "df_projP = pd.DataFrame(data=projP, index=protein_name, columns=cell_name)\n",
    "df_projD = pd.DataFrame(data=projD, index=TF_name, columns=cell_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
